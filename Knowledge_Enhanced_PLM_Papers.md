### Knowledge Enhanced Pre-trained Language Model

* Pretrained Encyclopedia: Weakly supervised knowledge-pretrained language model, ICLR2020, [Paper](https://arxiv.org/pdf/1912.09637.pdf)
* K-BERT: Enabling Language Representation With Knowledge Graph, [Paper](https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuW.5594.pdf), [Code](https://github.com/autoliuweijie/K-BERT)
* K-ADAPTER: Infusing Knowledge into Pre-Trained Models with Adapters, [Paper](https://arxiv.org/pdf/2002.01808.pdf)


### 阅读理解&Knowledge&BERT
* Enhancing pre-trainedlanguage representations with rich knowledge for machinereading comprehension, [Paper](https://www.aclweb.org/anthology/P19-1226.pdf)
